---
title: "Multiple Regression Model"
author: "Guan-Yuan Wang"
date: "2020/9/5"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(data.table)
library(dplyr)
```

# Exploring different multiple regression models for house price prediction
```{r}
dataTesting <- fread("kc_house_test_data.csv")
dataTraining <- fread("kc_house_train_data.csv")
```

```{r}
dataTesting <- dataTesting %>% 
  mutate(bedrooms_squared = bedrooms * bedrooms,
         bed_bath_rooms = bedrooms * bathrooms,
         log_sqft_living = log(sqft_living),
         lat_plus_long = lat + long)

dataTraining <- dataTraining  %>% 
  mutate(bedrooms_squared = bedrooms * bedrooms,
         bed_bath_rooms = bedrooms * bathrooms,
         log_sqft_living = log(sqft_living),
         lat_plus_long = lat + long)


mean(dataTesting$bedrooms_squared)
mean(dataTesting$bed_bath_rooms)
mean(dataTesting$log_sqft_living)
mean(dataTesting$lat_plus_long)
```


```{r}
m1 <- lm(price ~ sqft_living + bedrooms + bathrooms +
           lat + long, dataTraining)

m2 <- lm(price ~ sqft_living + bedrooms + bathrooms +
           lat + long + bed_bath_rooms, dataTraining)

m3 <- lm(price ~ sqft_living + bedrooms + bathrooms +
           lat + long + bed_bath_rooms + bedrooms_squared +
           log_sqft_living + lat_plus_long, dataTraining)

summary(m1)
summary(m2)
summary(m3)
```


# Implementing gradient descent for multiple regression
```{r}
simpleModel <- lm(price ~ sqft_living, dataTraining)
simpleModel
plot(dataTraining$sqft_living,
     dataTraining$price,
     col = rgb(0.2, 0.4, 0.6, 0.4),
     main = 'Linear regression by gradient descent')
abline(simpleModel, col = 'blue')
```

```{r}
# learning rate and tolerance
alpha <- 7 * 10 ^(-12)
tolerance <-  2.5 * 10^7

# initialize coefficients
beta <- matrix(c(-47000, 1), nrow = 2)

# add a column of 1's for the intercept coefficient
feature <- cbind(1, matrix(dataTraining$sqft_living))
price <- matrix(dataTraining$price)

# gradient descent
converged <-  F
derivative <- c()

while(converged == F){
  # predict outcome
  predictions <- feature %*% beta
  # feature derivative
  errors <- predictions - dataTraining$price
  # initialize the gradient sum of squares
  gradient_sum_squares <- 0
  
  # while we haven't reached the tolerance yet, update each feature's weight
  for (i in 1:ncol(feature)){
    derivative[i] = 2 * (t(errors) %*% matrix(feature[,i]))
  }
  
  gradient_sum_squares <- (derivative * derivative) + gradient_sum_squares
  
  beta <- beta - matrix(alpha * derivative)
  
  gradient_magnitude = sqrt(gradient_sum_squares)
  
  if
  ( gradient_magnitude[1] < tolerance & gradient_magnitude[2] < tolerance) {
    converged = T
  }
}

print(beta)
```


```{r}
predPrice <- cbind(1, matrix(dataTesting$sqft_living)) %*% beta

predPrice[1]
dataTesting[1, "price"]
```

```{r}
# Calculate RSS
residuals <- predPrice - dataTesting[, "price"]
RSS <- sum(residuals * residuals)
```

```{r}
multipleModel <- lm(price ~ sqft_living + sqft_living15, dataTraining)
multipleModel
```



```{r}
# learning rate and tolerance
alpha <- 4 * 10 ^(-12)
tolerance <-  1 * 10^9

# initialize coefficients
beta <- matrix(c(-100000, 1, 1), nrow = 3)

# add a column of 1's for the intercept coefficient
feature <- cbind(1, matrix(dataTraining$sqft_living),
                 matrix(dataTraining$sqft_living15))
price <- matrix(dataTraining$price)

# gradient descent
converged <-  F
derivative <- c()

while(converged == F){
  # predict outcome
  predictions <- feature %*% beta
  # feature derivative
  errors <- predictions - dataTraining$price
  # initialize the gradient sum of squares
  gradient_sum_squares <- 0
  
  # while we haven't reached the tolerance yet, update each feature's weight
  for (i in 1:ncol(feature)){
    derivative[i] = 2 * (t(errors) %*% matrix(feature[,i]))
  }
  
  gradient_sum_squares <- (derivative * derivative) + gradient_sum_squares
  
  beta <- beta - matrix(alpha * derivative)
  
  gradient_magnitude = sqrt(gradient_sum_squares)
  
  if
  ( gradient_magnitude[1] < tolerance & gradient_magnitude[2] < tolerance &
    gradient_magnitude[3] < tolerance) {
    converged = T
  }
}

print(beta)
```


```{r}
predPrice <- cbind(1, matrix(dataTesting$sqft_living),
                   matrix(dataTesting$sqft_living15)) %*% beta

predPrice[1]
dataTesting[1, "price"]
```
```{r}
residuals <- predPrice - dataTesting[, "price"]
RSS.multiple <- sum(residuals * residuals)
RSS.multiple

RSS.multiple < RSS
```














